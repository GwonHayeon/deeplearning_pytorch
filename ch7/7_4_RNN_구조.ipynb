{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "torchtext = 0.6.0<br/>\n",
        "torch = 1.11.0"
      ],
      "metadata": {
        "id": "QRVNgtFe0L11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "!pip uninstall torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8xy_Lqey_iu",
        "outputId": "9498de57-c9cd-4f9b-b345-2c4b5af69940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/nvfuser/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.0.1+cu118.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? Y\n",
            "Y\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n",
            "Found existing installation: torchtext 0.15.2\n",
            "Uninstalling torchtext-0.15.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/torchtext-0.15.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchtext/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchtext-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0\n",
        "!pip install torch==1.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HZM9nol1zEkE",
        "outputId": "df49b35c-9fa5-4f17-b2eb-0acd1960ae5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Collecting torch (from torchtext==0.6.0)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchtext==0.6.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchtext==0.6.0) (0.41.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchtext\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sentencepiece-0.1.99 torch-2.0.1 torchtext-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvfuser",
                  "torch",
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.7.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch\n",
        "!pip show torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67djfdfWmfRf",
        "outputId": "f49ec35f-25f2-41ac-86f8-99495b8cb7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.0.1+cu118\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision, triton\n",
            "Name: torchtext\n",
            "Version: 0.15.2\n",
            "Summary: Text utilities and datasets for PyTorch\n",
            "Home-page: https://github.com/pytorch/text\n",
            "Author: PyTorch core devs and James Bradbury\n",
            "Author-email: jekbradbury@gmail.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, requests, torch, torchdata, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchtext\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "YKyDQ0Xmu63_",
        "outputId": "d52bf81b-9cd2-46d8-a87e-b067a075e159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (1.13.0)\n",
            "Collecting torch\n",
            "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Collecting torchtext\n",
            "  Using cached torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0\n",
            "    Uninstalling torch-1.13.0:\n",
            "      Successfully uninstalled torch-1.13.0\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.0\n",
            "    Uninstalling torchtext-0.14.0:\n",
            "      Successfully uninstalled torchtext-0.14.0\n",
            "Successfully installed torch-2.0.1 torchtext-0.15.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w75EM6MFiGJ8"
      },
      "outputs": [],
      "source": [
        "#3.라이브러리 호출\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 데이터 전처리\n",
        "import torchtext.data\n",
        "start = time.time()\n",
        "TEXT = torchtext.data.Field(lower=True, fix_length=200, batch_first=False)\n",
        "LABEL = torchtext.data.Field(sequential=False)"
      ],
      "metadata": {
        "id": "cEttUx9KkCZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. 데이터셋 준비\n",
        "from torchtext import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT,LABEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgVWDPTIiX6b",
        "outputId": "e4daa29f-1ae1-4724-d256-0bbd99e9714d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 9.68MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6 훈련 데이터셋 내용확인\n",
        "print(vars(train_data.examples[0])) #데이터의 내용을 보고자 할 때는 examples를 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8ai0djP0eN4",
        "outputId": "623717a3-5390-44ae-92d9-8a9288c5db81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['hlots', 'was', 'an', 'outstanding', 'series,', 'its', 'what', 'nypd', 'blue', 'will', 'never', 'be,', 'on', 'hlots', 'the', 'plots', 'are', 'real,', 'the', 'dialog', 'is', 'real,', 'the', 'relationships', 'are', 'real.', 'with', 'hlots', 'back', 'as', 'a', 'movie,', 'tying', 'up', 'all', 'the', 'loose', 'ends,', 'it', 'was', 'good', 'to', 'have', 'all', 'the', 'gang', 'back', 'together,', 'even', 'a', 'few', 'that', 'passed', 'away', 'show', 'up', '(wont', 'say', 'how)', 'the', 'storyline', 'was', 'fast', 'paced,', 'emotional', 'and', 'full', 'of', 'the', 'spirit', 'the', 'series', 'had', 'week', 'in', 'and', 'week', 'out.', 'homicide', ',', 'life', 'on', 'the', 'streets,', 'network', 'drama', 'at', 'its', 'best!!!!', '5', 'stars!!!!', 'thumbs', 'up', 'and', 'all', 'that.', 'thanks', 'nbc', 'for', 'giving', 'us', 'the', 'finally', 'we', \"didn't\", 'get!'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. 데이터셋 전처리 적용\n",
        "import string\n",
        "for example in train_data.examples:\n",
        "  text = [x.lower() for x in vars(example)['text']] #소문자로 변경\n",
        "  text = [x.replace(\"<br\",\"\") for x in text] #\"<br\"을 \"\"(공백) 으로 변경\n",
        "  text = [''.join(c for c in s if c not in string.punctuation) for s in text]\n",
        "  text = [s for s in text if s] #공백제거\n",
        "  vars(example)['text'] = text"
      ],
      "metadata": {
        "id": "OxFfUzAk0q76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.훈련과 검증 데이터 확인\n",
        "import random\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(0), split_ratio=0.8) #데이터셋을 훈련과 검증 용도로 분리"
      ],
      "metadata": {
        "id": "xNHsk1nZ1KCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9.데이터셋 개수 확인\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-D4Iw641a0i",
        "outputId": "1d99a549-99a5-4b15-ad45-505c16047e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10 단어집합 만들기\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None) #단어집합 생성\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vacabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vacabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiBh4Gmu2fX0",
        "outputId": "5b0a0320-5008-4ac3-86b6-5de948a5de31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vacabulary: 10002\n",
            "Unique tokens in LABEL vacabulary: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11. 테스트 데이터셋의 단어 집합 확인\n",
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VptoJrbZ3n_6",
        "outputId": "edb2b05c-d662-40cb-d8da-c56b7f7136d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7a0fc96340d0>>, {'<unk>': 0, 'pos': 1, 'neg': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12. 데이터셋 메모리로 가져오기\n",
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "embeding_dim = 100\n",
        "hidden_size = 300\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=BATCH_SIZE,device=device)"
      ],
      "metadata": {
        "id": "Z_HGdpzv3vFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13. 워드 임베딩 및 RNN 셀 정의\n",
        "class RNNCell_Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, hiddien_size):\n",
        "    super(RNNCell_Encoder, self).__init__()\n",
        "    self.rnn = nn.RNNCell(input_dim, hidden_size) #RNN 셀 구현을 위한 구문\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    bz = inputs.shape[1] #배치를 가져옴\n",
        "    ht = torch.zeros((bz, hidden_size)).to(device) #배치와 은닉층 뉴런의 크기를 0으로 초기화\n",
        "    for word in inputs:\n",
        "      ht = self.rnn(word,ht) #재귀적으로 발생하는 상태 값을 처리하기 위한 구문\n",
        "    return ht\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.em = nn.Embedding(len(TEXT.vocab.stoi), embeding_dim)\n",
        "    self.rnn = RNNCell_Encoder(embeding_dim, hidden_size)\n",
        "    self.fc1 = nn.Linear(hidden_size,256)\n",
        "    self.fc2 = nn.Linear(256,3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.em(x)\n",
        "    x=self.rnn(x)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=self.fc2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "XLWapkuj4_lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14 옵티마이저와 손실함수 정의\n",
        "model = Net() #model 이라는 이름으로 모델을 객체화\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)"
      ],
      "metadata": {
        "id": "0wmu5zYW60Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15. 모델 학습을 위한 함수 정의\n",
        "def training(epoch, model, trainloader, validloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  running_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  for b in trainloader:\n",
        "    x,y = b.text, b.label\n",
        "    x,y = x.to(device), y.to(device) #꺼내온 데이터가 CPU를 사용할 수 있도록 장치 지정\n",
        "    y_pred =model(x)\n",
        "    loss = loss_fn(y_pred,y)#CrossEntropyLoss 손실 함수를 이용하여 dh차 계산\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      y_pred = torch.argmax(y_pred, dim=1)\n",
        "      correct += (y_pred == y).sum().item()\n",
        "      total += y.size(0)\n",
        "      running_loss += loss.item()\n",
        "  epoch_loss = running_loss / len(trainloader.dataset) #누적된 오차를 전체 데이터셋으로 나누어서 에포크 단계마다 오차를 구함\n",
        "  epoch_acc = correct/total\n",
        "\n",
        "  valid_correct = 0\n",
        "  valid_total = 0\n",
        "  valid_running_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for b in validloader:\n",
        "      x,y = b.text, b.label\n",
        "      x,y = x.to(device), y.to(device)\n",
        "      y_pred = model(x)\n",
        "      loss = loss_fn(y_pred,y)\n",
        "      y_pred = torch.argmax(y_pred, dim=1)\n",
        "      valid_correct += (y_pred == y).sum().item()\n",
        "      valid_total +=  y.size(0)\n",
        "      valid_running_loss += loss.item()\n",
        "  epoch_valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "  epoch_valid_acc = valid_correct / valid_total\n",
        "\n",
        "  print('epoch: ', epoch,\n",
        "        'loss: ', round(epoch_acc, 3),\n",
        "        'valid_loss: ',round(epoch_valid_loss,3),\n",
        "        'valid_accuracy: ', round(epoch_valid_acc,3)) #훈련이 진행될 때 에포크마다 정확도와 오차 출력\n",
        "  return epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc"
      ],
      "metadata": {
        "id": "xYaCPD_t7QkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16 모델학습\n",
        "epochs = 5\n",
        "train_loss =[]\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc = training(epoch, model, train_iterator, valid_iterator)\n",
        "  train_loss.append(epoch_loss)\n",
        "  train_acc.append(epoch_acc) #훈련 데이터셋을 모델에 적용했을 때의 정확도\n",
        "  valid_loss.append(epoch_valid_loss) #검증 데이터셋을 모델에 적용했을 때의 오차\n",
        "  valid_acc.append(epoch_valid_acc) #검증 데이터셋을 모델에 적용했을 때의 정확도\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfgbXNLkVMFR",
        "outputId": "13dcfa6f-1e76-4f93-e50d-884df493e069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss:  0.492 valid_loss:  0.017 valid_accuracy:  0.498\n",
            "epoch:  1 loss:  0.492 valid_loss:  0.017 valid_accuracy:  0.498\n",
            "epoch:  2 loss:  0.492 valid_loss:  0.017 valid_accuracy:  0.498\n",
            "epoch:  3 loss:  0.492 valid_loss:  0.017 valid_accuracy:  0.498\n",
            "epoch:  4 loss:  0.492 valid_loss:  0.017 valid_accuracy:  0.498\n",
            "921.6783285140991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17 모델 예측 함수 정의\n",
        "def evaluate(epoch, model, testloader):\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  test_running_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for b in testloader:\n",
        "      x,y = b.text, b.label\n",
        "      x,y = x.to(device), y.to(device)\n",
        "      y_pred = model(x)\n",
        "      loss = loss_fn(y_pred,y)\n",
        "      y_pred = torch.argmax(y_pred, dim=1)\n",
        "      test_correct += (y_pred==y).sum().item()\n",
        "      test_total += y.size(0)\n",
        "      test_running_loss += loss.item()\n",
        "\n",
        "  epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
        "  epoch_test_acc = test_correct / test_total\n",
        "\n",
        "  print('epoch: ',epoch, 'test_loss: ',round(epoch_test_loss, 3), 'test_accuracy: ', round(epoch_test_acc, 3))\n",
        "  return epoch_test_loss, epoch_test_acc"
      ],
      "metadata": {
        "id": "BrGqXW80WehC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18 모델 예측 결과 확인\n",
        "epochs = 5\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs) :\n",
        "  epoch_test_loss, epoch_test_acc = evaluate(epoch, model, test_iterator)\n",
        "  test_loss.append(epoch_test_loss)\n",
        "  test_acc.append(epoch_test_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK5DmMtPZV_a",
        "outputId": "6d7466e0-3e68-429c-944d-064bad5ac739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 test_loss:  0.017 test_accuracy:  0.484\n",
            "epoch:  1 test_loss:  0.017 test_accuracy:  0.484\n",
            "epoch:  2 test_loss:  0.017 test_accuracy:  0.484\n",
            "epoch:  3 test_loss:  0.017 test_accuracy:  0.484\n",
            "epoch:  4 test_loss:  0.017 test_accuracy:  0.484\n",
            "1630.262906074524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7.4.2 RNN 계층 구현\n",
        "#19. 라이브러리 호출\n",
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import torch.nn as np\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "E_kNOcNoZcxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20 데이터셋 내려받기 및 전처리\n",
        "start = time.time()\n",
        "TEXT = torchtext.data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = torchtext.data.Field(sequential=False, batch_first=True)\n",
        "\n",
        "from torchtext import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(split_ratio=0.8)\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10,vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "kwYPhP-5bDnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21 데이터셋 분리\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits((train_data,valid_data, test_data), batch_size=BATCH_SIZE, device=device)"
      ],
      "metadata": {
        "id": "il9BeynvcNeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22 변수 값 지정\n",
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes=2 #pos 긍정 neg부정"
      ],
      "metadata": {
        "id": "5TNWJCH0ceET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23 RNN 계층 네트워크\n",
        "class BasicRNN(nn.Module):\n",
        "  def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "    super(BasicRNN, self).__init__()\n",
        "    self.n_layers =n_layers #RNN 계층에 대한 개수\n",
        "    self.embed = nn.Embedding(n_vocab, embed_dim) #워드 임베딩 적용\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.dropout = nn.Dropout(dropout_p) #드롭아웃 적용\n",
        "    self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
        "    self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.embed(x)\n",
        "    h_0 = self._init_state(batch_size=x.size(0)) #최초의 은닉 상태의 값을 0으로 초기화\n",
        "    x, _ = self.rnn(x,h_0) #RNN 계층을 의미하며 파라미터로 입력과 이전 은닉 상태의 값을 받는다\n",
        "    h_t = x[:,-1,:] #모든 네트워크를 거쳐서 가장 마지막에 나온 단어의 임베딩 값\n",
        "    self.dropout(h_t)\n",
        "    logit = torch.sigmoid(self.out(h_t))\n",
        "    return logit\n",
        "\n",
        "  def _init_state(self, batch_size=1):\n",
        "    weight = next(self.parameters()).data #모델의 파라미터 값을 가져와서 weight변수에 저장\n",
        "    return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_() #크기가 (계층개수, 배치크기, 은닉청뉴런/유닛 개수)인 은닉 텐서를 생성하여 0으로 초기화 후 반환"
      ],
      "metadata": {
        "id": "Q_M40KpHclf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24 손실함수와 옵티마이저 설정\n",
        "model = BasicRNN(n_layers = 1, hidden_dim=256, n_vocab=vocab_size, embed_dim=128, n_classes=n_classes, dropout_p=0.5)\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)"
      ],
      "metadata": {
        "id": "acCzo0AdeUhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25 모델 학습 함수\n",
        "def train(model, optimizer, train_iter):\n",
        "  model.train()\n",
        "  for b, batch in enumerate(train_iter):\n",
        "    x,y=batch.text.to(device), batch.label.to(device)\n",
        "    y.data.sub_(1)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logit = model(x)\n",
        "    loss = F.cross_entropy(logit, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if b % 50 == 0: #훈련 데이터셋의 개수를 50으로 나누어서 나머지가 0이면 출력\n",
        "      print(\"Train Epoch: {}[{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(e, b*len(x),len(train_iter.dataset),b*len(x)/len(train_iter.dataset),loss.item()))"
      ],
      "metadata": {
        "id": "LEZjJOxfe0uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26 모델 평가 함수\n",
        "def evaluate(model, val_iter):\n",
        "  model.eval()\n",
        "  corrects, total, total_loss = 0,0,0\n",
        "\n",
        "  for batch in val_iter:\n",
        "    x,y = batch.text.to(device), batch.label.to(device)\n",
        "    y.data.sub_(1)\n",
        "    logit = model(x)\n",
        "    loss = F.cross_entropy(logit, y, reduction=\"sum\")\n",
        "    total += y.size(0)\n",
        "    total_loss += loss.item()\n",
        "    corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum() #모델의 정확도\n",
        "\n",
        "  avg_loss = total_loss / len(val_iter.dataset)\n",
        "  avg_accuracy = corrects / total\n",
        "  return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "6Tkg-m2zfe7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#27 모델 학습 및 평가\n",
        "BATCH_SIZE = 100\n",
        "LR = 0.001\n",
        "EPOCHS = 5\n",
        "for e in range(1,EPOCHS+1):\n",
        "  train(model, optimizer, train_iterator)\n",
        "  val_loss, val_accuracy = evaluate(model, valid_iterator)\n",
        "  print(\"[EPOCH: %d], Validation Loss: %5.2f | Validation Accuracy: %5.2f\" % (e, val_loss,  val_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkZiuFL1gUCK",
        "outputId": "de84f311-272b-4bb3-8993-a576fc2ce42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1[0/20000 (0%)]\tLoss: 0.692940\n",
            "Train Epoch: 1[5000/20000 (0%)]\tLoss: 0.694158\n",
            "Train Epoch: 1[10000/20000 (0%)]\tLoss: 0.693275\n",
            "Train Epoch: 1[15000/20000 (1%)]\tLoss: 0.692499\n",
            "[EPOCH: 1], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 2[0/20000 (0%)]\tLoss: 0.690685\n",
            "Train Epoch: 2[5000/20000 (0%)]\tLoss: 0.691833\n",
            "Train Epoch: 2[10000/20000 (0%)]\tLoss: 0.693434\n",
            "Train Epoch: 2[15000/20000 (1%)]\tLoss: 0.692564\n",
            "[EPOCH: 2], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 3[0/20000 (0%)]\tLoss: 0.693732\n",
            "Train Epoch: 3[5000/20000 (0%)]\tLoss: 0.692089\n",
            "Train Epoch: 3[10000/20000 (0%)]\tLoss: 0.689370\n",
            "Train Epoch: 3[15000/20000 (1%)]\tLoss: 0.693285\n",
            "[EPOCH: 3], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 4[0/20000 (0%)]\tLoss: 0.697780\n",
            "Train Epoch: 4[5000/20000 (0%)]\tLoss: 0.691039\n",
            "Train Epoch: 4[10000/20000 (0%)]\tLoss: 0.692637\n",
            "Train Epoch: 4[15000/20000 (1%)]\tLoss: 0.692598\n",
            "[EPOCH: 4], Validation Loss:  0.69 | Validation Accuracy:  0.51\n",
            "Train Epoch: 5[0/20000 (0%)]\tLoss: 0.693300\n",
            "Train Epoch: 5[5000/20000 (0%)]\tLoss: 0.691744\n",
            "Train Epoch: 5[10000/20000 (0%)]\tLoss: 0.693350\n",
            "Train Epoch: 5[15000/20000 (1%)]\tLoss: 0.692028\n",
            "[EPOCH: 5], Validation Loss:  0.69 | Validation Accuracy:  0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2-r5SqOgy88"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}