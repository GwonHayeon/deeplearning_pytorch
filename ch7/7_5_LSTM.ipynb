{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5.1 LSTM 구조\n",
        "\n",
        "**LSTM 순전파**<br>\n",
        "기울기 소멸 문제를 해결하기 위해 망각 게이트, 입력 게이트 출력 게이트라는 새로운 요소를 은닉층의 각 뉴런에 추가\n",
        "\n",
        "**망각 게이트** <br>\n",
        "과거 정보를 어느정도 기억할지 결정. 과거 정보와 현재 데이터를 입력받아 시그모이드를 취한 후 그 값을 과거 정보에 곱해줌. 출력이 0이면 정보는 버리고 1이면 보존\n",
        "\n",
        "- 계산한 값이 1이면 바로 직전의 정보를 메모리에 유지\n",
        "- 계산한 값이 0이면 초기화\n",
        "\n",
        "**입력 게이트** <br>\n",
        "입력 게이트는 현재 정보를 기억하기 위해 만들어짐. 과거 정보와 현재 데이터를 입력받아 시그모이드와 하이퍼볼릭 탄젠트 함수를 기반으로 현재 정보에 대한 보존량 결정\n",
        "즉 현재 메모리에 새로운 정보를 반영할지 결정하는 역할을 함\n",
        "\n",
        "- 계산한 값이 1이면 입력x_t가 들어올 수 있도록 허용\n",
        "- 계산한 값이 0이면 차단\n",
        "\n",
        "**셀** <br>\n",
        "각 단계에 대한 은닉 노드를 메모리셀이라 함. 총압을 사용하여 셀 값을 반영하여 이것으로 기울기 소멸 문제가 해결.<br>\n",
        "셀 업데이트 방법<br>\n",
        ":: 망각 게이트와 입력 게이트의 이전 단계 셀 정보를 계산하여 현재 단계의 셀 상태 업데이트\n",
        "\n",
        "**출력 게이트** <br>\n",
        "과거 정보와 현재 데이터를 사용하여 출력 결정. 이전 은닉 상태와 t번째 출력을 고려해서 다음 은닉 상태 계산. LSTM에서는 은닉 상태가 그 시점에서의 출력이 됨.<br>\n",
        "출력게이트는 갱신된 메모리의 출력 값을 제어하는 역할을 함<br>\n",
        "- 계산한 값이 1이면 의미 있는 결과로 최종 출력\n",
        "- 계산한 값이 0이면 해당 연산출력을 하지않음\n",
        "\n"
      ],
      "metadata": {
        "id": "hhlWZtB5qB4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QTB7IPJ3psYw"
      },
      "outputs": [],
      "source": [
        "#29. 라이브러리 호출\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter #파라미터 목록을 갖고 있는 라이브러리(패키지)\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import math #수학과 관련되어 다양한 함수들과 상수들이 정의되어 있는 라이브러리\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = True if torch.cuda.is_available() else False #GPU 사용에 필요\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor #GPU사용에 필요\n",
        "\n",
        "torch.manual_seed(125)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(125)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. 데이터 전처리\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(1.0,)) #평균을 0.5, 표준편차를 1.0으로 데이터 정규화\n",
        "])"
      ],
      "metadata": {
        "id": "Q2pe1vhifZxv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#31. 데이터 내려받기\n",
        "from torchvision.datasets import MNIST\n",
        "#data_dir = '/content/drive/MyDrive/Colab Notebooks/MNIST_DATASET'\n",
        "\n",
        "download_root='/content/drive/MyDrive/Colab Notebooks/MNIST_DATASET'\n",
        "\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True) #내려받을 위치 지정, 전처리 적용, 훈련용데이터, 파일이 없을때 내려받기\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
      ],
      "metadata": {
        "id": "w1dAvvZQgMNO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#32 데이터셋을 메모리로 가져오기\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "vaild_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "PWXMvPPlhUmA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#33 변수값 지정\n",
        "batch_size = 100\n",
        "n_iters = 6000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)"
      ],
      "metadata": {
        "id": "h8TI2BpFhqMN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#34 LSTM 셀 네트워크 구축\n",
        "class LSTMCell(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, bias=True):\n",
        "    super(LSTMCell, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "    self.x2h = nn.Linear(input_size, 4*hidden_size, bias = bias)\n",
        "    self.h2h = nn.Linear(hidden_size, 4*hidden_size, bias = bias)\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    std = 1.0/math.sqrt(self.hidden_size)\n",
        "    for w in self.parameters():\n",
        "      w.data.uniform_(-std, std)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    hx, cx = hidden\n",
        "    x = x.view(-1, x.size(1))\n",
        "\n",
        "    gates = self.x2h(x) + self.h2h(hx)\n",
        "    gates = gates.squeeze()\n",
        "    ingate, forgetgate, cellgate, outgate = gates.chunk(4,1)\n",
        "\n",
        "    ingate = F.sigmoid(ingate) #입력 게이트에 시그모이드 활성화 함수 적용\n",
        "    forgetgate = F.sigmoid(forgetgate ) #망각 게이트에 시그모이드 활성화 함수 적용\n",
        "    cellgate = F.tanh(cellgate) #셀 게이트에 탄젠트 활성화 함수 적용\n",
        "    outgate = F.sigmoid(outgate) #출력 게이트에 시그모이드 활성화 함수 적용\n",
        "\n",
        "    cy = torch.mul(cx, forgetgate) + torch.mul(ingate, cellgate) #4.\n",
        "    hy = torch.mul(outgate, F.tanh(cy)) #4`\n",
        "    return(hy,cy)"
      ],
      "metadata": {
        "id": "ZYQjw0T5h1bM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#35 LSTM 셀의 전반적인 네트워크\n",
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias = True):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.hidden_dim = hidden_dim #은닉층의 뉴런/유닛 개수\n",
        "\n",
        "    self.layer_dim = layer_dim\n",
        "    self.lstm = LSTMCell(input_dim, hidden_dim, layer_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    if torch.cuda.is_available(): #GPU 사용 유무 확인\n",
        "      h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()) #은닉상태를 0으로 초기화\n",
        "    else:\n",
        "      h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "\n",
        "    if torch.cuda.is_available(): #GPU 사용 유무 확인\n",
        "      c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()) #셀 상태를 0으로 초기화\n",
        "    else:\n",
        "      c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "\n",
        "    outs = []\n",
        "    cn = c0[0,:,:] #셀 상태에 대한 텐서\n",
        "    hn = h0[0,:,:] #은닉 상태에 대한 텐서\n",
        "\n",
        "    for seq in range(x.size(1)): #LSTM 셀 계층을 반복하여 쌓아올린다\n",
        "      hn, cn = self.lstm(x[:,seq,:],(hn,cn))\n",
        "      outs.append(hn)\n",
        "\n",
        "    out = outs[-1].squeeze()\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ODkH0zqyjvXT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#36. 옵티마이저와 손실 함수 지정\n",
        "input_dim = 28\n",
        "hidden_dim = 128\n",
        "layer_dim = 1\n",
        "output_dim = 10\n",
        "\n",
        "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "3F0XlKcH9mOn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#37. 모델 학습 및 성능확인\n",
        "seq_dim = 28\n",
        "loss_list = []\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader): #훈련데이터셋을 이용한 모델학습\n",
        "    if torch.cuda.is_available():\n",
        "      images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "      labels = Variable(labels.cuda())\n",
        "    else:\n",
        "      images = Variable(images.view(-1, seq_dim, input_dim))\n",
        "      labels = Variable(labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels) #손실함수를 이용하여 오차계산\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      loss.cuda()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step() #파라미터 업데이트\n",
        "    loss_list.append(loss.item())\n",
        "    iter += 1\n",
        "\n",
        "    if iter % 500 == 0: #정확도 계산\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in vaild_loader: #검증 데이터셋을 이용한 모델 성능 검증\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "        else:\n",
        "          images = Variable(images.view(-1, seq_dim, input_dim))\n",
        "        outputs = model(images)\n",
        "        _,predicted = torch.max(outputs.data ,1) #모델을 통과한 결과의 최댓값으로부터 예측결과 가져오기\n",
        "\n",
        "        total += labels.size(0) #총 레이블 수\n",
        "        if torch.cuda.is_available():\n",
        "          correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "        else:\n",
        "          correct += (predicted == labels).sum()\n",
        "\n",
        "      accuracy = 100*correct/total\n",
        "      print(\"Iteration: {}. Loss: {}. Accuracy: {}\".format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hgnWk98-UKN",
        "outputId": "e1098037-8062-4384-eabc-ba605241f0c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 2.2252509593963623. Accuracy: 17.09000015258789\n",
            "Iteration: 1000. Loss: 0.8516435623168945. Accuracy: 74.45999908447266\n",
            "Iteration: 1500. Loss: 0.29393482208251953. Accuracy: 89.37999725341797\n",
            "Iteration: 2000. Loss: 0.14795789122581482. Accuracy: 94.13999938964844\n",
            "Iteration: 2500. Loss: 0.2517714202404022. Accuracy: 94.73999786376953\n",
            "Iteration: 3000. Loss: 0.21248352527618408. Accuracy: 95.08999633789062\n",
            "Iteration: 3500. Loss: 0.252878874540329. Accuracy: 95.58999633789062\n",
            "Iteration: 4000. Loss: 0.057503774762153625. Accuracy: 96.62999725341797\n",
            "Iteration: 4500. Loss: 0.05089123547077179. Accuracy: 97.19999694824219\n",
            "Iteration: 5000. Loss: 0.02951515093445778. Accuracy: 97.1500015258789\n",
            "Iteration: 5500. Loss: 0.133195161819458. Accuracy: 97.73999786376953\n",
            "Iteration: 6000. Loss: 0.0890934020280838. Accuracy: 97.75\n",
            "Iteration: 6500. Loss: 0.03826271742582321. Accuracy: 97.77999877929688\n",
            "Iteration: 7000. Loss: 0.012725875712931156. Accuracy: 97.87999725341797\n",
            "Iteration: 7500. Loss: 0.02836068905889988. Accuracy: 97.69999694824219\n",
            "Iteration: 8000. Loss: 0.10693557560443878. Accuracy: 98.0999984741211\n",
            "Iteration: 8500. Loss: 0.043992072343826294. Accuracy: 97.66999816894531\n",
            "Iteration: 9000. Loss: 0.015313017182052135. Accuracy: 97.9000015258789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "  corrects, total, total_loss = 0, 0, 0\n",
        "  model.eval()\n",
        "  for images, labels in val_iter:\n",
        "    if torch.cuda.is_available():\n",
        "      images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "      labels = labels.cuda()  # Move labels to the GPU\n",
        "    else:\n",
        "      images = Variable(images.view(-1, seq_dim, input_dim)).to(device)\n",
        "\n",
        "    logit = model(images).to(device)\n",
        "    loss = F.cross_entropy(logit, labels, reduction=\"sum\")\n",
        "    _, predicted = torch.max(logit.data, 1)\n",
        "    total += labels.size(0)\n",
        "    total_loss += loss.item()\n",
        "    corrects += (predicted == labels).sum()\n",
        "\n",
        "  avg_loss = total_loss / len(val_iter.dataset)\n",
        "  avg_accuracy = corrects / total\n",
        "  return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "Rom0-6vJpcfU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#39 모델 예측 성능 확인\n",
        "test_loss, test_acc = evaluate(model, test_loader)\n",
        "print(\"Test Loss : %5.2f | Test Accuracy : %5.2f\" % (test_loss, test_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeNsLVwiEbRz",
        "outputId": "ef28c7bc-57f9-45cb-f4f2-19fb13150eff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss :  0.06 | Test Accuracy :  0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsfyzigmEtjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}