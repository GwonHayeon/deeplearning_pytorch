{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c8964b",
   "metadata": {},
   "source": [
    "### 7.6.3 GRU 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d0f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#63 라이브러리 호출\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2956e66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date          object\n",
      "Open         float64\n",
      "High         float64\n",
      "Low          float64\n",
      "Close        float64\n",
      "Adj Close    float64\n",
      "Volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#64 데이터셋 불러오기\n",
    "data = pd.read_csv(\"SBUX.csv\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78893aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#65 인덱스 설정 및 데이터타입 변경\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "data['Volume'] = data['Volume'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aafba1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close\n",
      "Date                                                                  \n",
      "2019-12-11   86.260002   86.870003   85.849998   86.589996   84.145752\n",
      "2019-12-12   88.000000   88.889999   87.540001   88.209999   85.720032\n",
      "2019-12-13   88.019997   88.790001   87.580002   88.669998   86.167046\n",
      "2019-12-16   89.139999   89.300003   88.430000   88.779999   86.273941\n",
      "2019-12-17   88.870003   88.970001   87.470001   88.129997   85.642288\n",
      "...                ...         ...         ...         ...         ...\n",
      "2020-12-04  101.349998  102.940002  101.070000  102.279999  101.442787\n",
      "2020-12-07  102.010002  102.220001  100.690002  101.410004  100.579918\n",
      "2020-12-08  100.370003  101.570000  100.010002  101.209999  100.381554\n",
      "2020-12-09  101.940002  102.209999  100.099998  100.400002   99.578186\n",
      "2020-12-10  103.510002  106.089996  102.750000  105.389999  104.527336\n",
      "\n",
      "[253 rows x 5 columns]\n",
      "                Volume\n",
      "Date                  \n",
      "2019-12-11   4921900.0\n",
      "2019-12-12  10282100.0\n",
      "2019-12-13   6714100.0\n",
      "2019-12-16   6705600.0\n",
      "2019-12-17   7296900.0\n",
      "...                ...\n",
      "2020-12-04   6952700.0\n",
      "2020-12-07   4514800.0\n",
      "2020-12-08   3911300.0\n",
      "2020-12-09   6629900.0\n",
      "2020-12-10  12939200.0\n",
      "\n",
      "[253 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#68 훈련과 레이블 데이터셋 분리\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,5:6]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a56422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape (200, 5) (200, 1)\n",
      "Testing Shape (53, 5) (53, 1)\n"
     ]
    }
   ],
   "source": [
    "#67 훈련과 테스트 데이터셋 정규화\n",
    "ms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "y_ms = ms.fit_transform(y)\n",
    "\n",
    "X_train = X_ss[:200,:]\n",
    "X_test = X_ss[200:, :]\n",
    "\n",
    "y_train = y_ms[:200,:]\n",
    "y_test = y_ms[200:, :]\n",
    "\n",
    "print(\"Training Shape\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Shape\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7217df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([200, 1, 5]) torch.Size([200, 1])\n",
      "Testing Shape torch.Size([53, 1, 5]) torch.Size([53, 1])\n"
     ]
    }
   ],
   "source": [
    "#68 데이터셋 형태 변경\n",
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train_tensors =Variable(torch.Tensor(y_train))\n",
    "y_test_tensors =Variable(torch.Tensor(y_test))\n",
    "\n",
    "X_train_tensors_f = torch.reshape(X_train_tensors, (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_f = torch.reshape(X_test_tensors, (X_test_tensors.shape[0], 1, X_test_tensors.shape[1]))\n",
    "\n",
    "print(\"Training Shape\", X_train_tensors_f.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_f.shape, y_test_tensors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "393bb1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        output, hn = self.gru(x, h_0)\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.fc(hn)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e31ed181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#69 GRU 모델의 네트워크\n",
    "class GRU(nn.Module) :\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.gru = nn.GRU(input_size = input_size, hidden_size = hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_size,128)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        output, (hn) = self.gru(x,(h_0))\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a91c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#70 옵티마이저와 손실함수 지정\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "\n",
    "model = GRU(num_classes, input_size, hidden_size, num_layers, X_train_tensors_f.shape[1])\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1850c323",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 4, got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#71 모델 학습\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensors_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train_tensors)\n",
      "Cell \u001b[1;32mIn[36], line 18\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m     17\u001b[0m     h_0 \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size))\n\u001b[1;32m---> 18\u001b[0m     output, (hn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     hn \u001b[38;5;241m=\u001b[39m hn\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m     20\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(hn)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:940\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    938\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 940\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    942\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    943\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:229\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pyTest\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    203\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    207\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 4, got 5"
     ]
    }
   ],
   "source": [
    "#71 모델 학습\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model.forward(X_train_tensors_f)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, y_train_tensors)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch : %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9684c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
